# Задание 1 ----

# Устанавливаем параметры и начальные значения
set.seed(123)  # Фиксируем случайные значения для повторяемости эксперимента
n <- 2100  # Количество наблюдений
theta <- c(-0.3, 0.4)  # Параметры AR(2)
A <- c(1, 0.2, 0.1, 0.2)  # Параметры ARCH(3)

# Генерируем шум для модели - независимые нормальные случайные величины
epsilon <- rnorm(n)

# Создаем векторы для хранения значений
x <- rep(0, n)
sigma2 <- rep(0, n)

# Инициализируем начальные значения для sigma^2 и x
# Первый раз просто берем дисперсию шума для начальных значений
sigma2[1:3] <- var(epsilon)
x[1:3] <- rnorm(3)  # Случайно инициализируем первые значения x

# Генерация процесса AR(2)ARCH(3)
for (i in 4:n) {
  # Важно помнить: sigma^2 зависит от прошлых значений x (ARCH(3) часть)
  sigma2[i] <- A[1] + A[2] * x[i-1]^2 + A[3] * x[i-2]^2 + A[4] * x[i-3]^2
  # Теперь генерируем x с учетом модели AR(2) и шума с дисперсией sigma^2
  x[i] <- theta[1] * x[i-1] + theta[2] * x[i-2] + sqrt(sigma2[i]) * epsilon[i]
}

# Построим график полученного ряда
plot(x, type = "l", col = "blue", main = "AR(2)ARCH(3) процесс", xlab = "Время", ylab = "x_n")


# Задание 2 ----

# Количество наблюдений в обучающей выборке (в отношении 20:1)
train_size <- floor(20/21 * n)  # Рассчитываем размер обучающей выборки
test_size <- n - train_size  # Размер тестовой выборки

# Разделение на обучающую и тестовую выборки
train_data <- x[1:train_size]  # Первые 2000 наблюдений (примерно 20:1)
test_data <- x[(train_size + 1):n]  # Остальные наблюдения

# Вывод размеров выборок для проверки
cat("Размер обучающей выборки:", length(train_data), "\n")
cat("Размер тестовой выборки:", length(test_data), "\n")

# Дополнительно, можем визуально посмотреть, как разделение повлияло на данные
plot(train_data, type = "l", col = "green", main = "Обучающая выборка", xlab = "Время", ylab = "x_train")
plot(test_data, type = "l", col = "red", main = "Тестовая выборка", xlab = "Время", ylab = "x_test")


# Задание 3 ---- 

# Шаг 3a: Оценка параметров theta с помощью функции arima()
# Здесь мы используем встроенную функцию arima(), чтобы не писать всё вручную
ar_model <- arima(train_data, order = c(2, 0, 0))  # AR(2) модель
theta_hat <- coef(ar_model)[1:2]  # Оценка параметров theta

# Выводим оцененные параметры
cat("Оценка параметров theta через arima():", theta_hat, "\n")

# Проверим невязки, чтобы убедиться, что модель правильно настроена
residuals <- residuals(ar_model)
plot(residuals, type = "l", col = "purple", main = "Остатки AR(2) модели", xlab = "Время", ylab = "Невязки")


# Шаг 3b: Оценка параметров A с помощью функции garch()

# Используем невязки (остатки) для оценки параметров ARCH(3)
# Здесь мы применяем функцию garch() к ошибкам модели AR(2)
library(tseries)  # Подгружаем пакет для использования функции garch
garch_model <- garch(residuals, order = c(0, 3))  # ARCH(3) модель
A_hat <- coef(garch_model)  # Оценка параметров A

# Выводим оцененные параметры A
cat("Оценка параметров A через garch():", A_hat, "\n")

# Построим график оцененной дисперсии
sigma_hat <- fitted(garch_model)[,1]^2  # Оцененные значения дисперсии
plot(sigma_hat, type = "l", col = "orange", main = "Оцененная дисперсия ARCH(3)", xlab = "Время", ylab = "Sigma^2")

